import { CustomTransportStrategy, KafkaParser, KafkaParserConfig, OutgoingResponse, ReadPacket, Server } from '@nestjs/microservices';
import * as kafkaLib from '@confluentinc/kafka-javascript';
import { Logger } from '@nestjs/common';
import { Deserializer } from '@nestjs/microservices/interfaces/deserializer.interface';
import { Serializer } from '@nestjs/microservices/interfaces/serializer.interface';
import { EachMessagePayload, Message, RecordMetadata } from '@nestjs/microservices/external/kafka.interface';
import { ConfluentKafkaContext } from './confluent-kafka-context';
import { Observable, ReplaySubject } from 'rxjs';
type MakePropRequired<T, K extends keyof T> = Omit<T, K> & Required<Pick<T, K>>;
type MakePropOptional<T, K extends keyof T> = Omit<T, K> & Partial<Pick<T, K>>;
export type KafkaServerOptions = {
    server: MakePropRequired<kafkaLib.KafkaJS.CommonConstructorConfig, 'bootstrap.servers'>;
    consumer?: MakePropOptional<kafkaLib.KafkaJS.ConsumerConfig, 'groupId'>;
    subscribe?: kafkaLib.KafkaJS.ConsumerSubscribeTopics;
    run?: kafkaLib.KafkaJS.ConsumerRunConfig;
    producer?: kafkaLib.KafkaJS.ProducerConfig;
    parser?: KafkaParserConfig;
    serializer?: Serializer;
    deserializer?: Deserializer;
    postfixId?: string;
};
export declare class ConfluentKafkaServer extends Server implements CustomTransportStrategy {
    protected readonly options: KafkaServerOptions;
    readonly logger: Logger;
    protected client: kafkaLib.KafkaJS.Kafka;
    protected consumer: kafkaLib.KafkaJS.Consumer;
    protected producer: kafkaLib.KafkaJS.Producer;
    protected admin: kafkaLib.KafkaJS.Admin;
    protected parser: KafkaParser;
    protected clientId: string;
    protected groupId: string;
    constructor(options: KafkaServerOptions);
    listen(callback?: (err?: unknown, ...optionalParams: unknown[]) => void): Promise<void>;
    createClient(): kafkaLib.KafkaJS.Kafka;
    start(callback?: () => void): Promise<void>;
    bindEvents(consumer: kafkaLib.KafkaJS.Consumer): Promise<void>;
    getMessageHandler(): kafkaLib.KafkaJS.EachMessageHandler;
    handleMessage(payload: EachMessagePayload): Promise<any>;
    handleEvent(pattern: string, packet: ReadPacket, context: ConfluentKafkaContext): Promise<any>;
    getPublisher(replyTopic: string, replyPartition: string, correlationId: string): (data: any) => Promise<RecordMetadata[]>;
    sendMessage(message: OutgoingResponse, replyTopic: string, replyPartition: string, correlationId: string): Promise<RecordMetadata[]>;
    assignIsDisposedHeader(outgoingResponse: OutgoingResponse, outgoingMessage: Message): void;
    assignCorrelationIdHeader(correlationId: string, outgoingMessage: Message): void;
    assignReplyPartition(replyPartition: string, outgoingMessage: Message): void;
    assignErrorHeader(outgoingResponse: OutgoingResponse, outgoingMessage: Message): void;
    protected combineStreamsAndThrowIfRetriable(response$: Observable<any>, replayStream$: ReplaySubject<unknown>): Promise<void>;
    close(): Promise<void>;
    protected initializeSerializer(serializer?: Serializer): void;
    protected initializeDeserializer(deserializer?: Deserializer): void;
    on(_event: any, _callback: any): any;
    unwrap<T>(): T;
}
export {};
